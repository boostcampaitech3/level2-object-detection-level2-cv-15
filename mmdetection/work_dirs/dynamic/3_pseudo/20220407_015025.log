2022-04-07 01:50:26,673 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0: Tesla V100-PCIE-32GB
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.7.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2
OpenCV: 4.5.5
MMCV: 1.4.8
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMDetection: 2.22.0+6ddbff8
------------------------------------------------------------

2022-04-07 01:50:28,021 - mmdet - INFO - Distributed training: False
2022-04-07 01:50:29,318 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '../dataset/'
classes = [
    'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic',
    'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'
]
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
albu_train_transforms = [
    dict(
        type='OneOf',
        transforms=[
            dict(type='Flip', p=1.0),
            dict(type='RandomRotate90', p=1.0)
        ],
        p=0.5),
    dict(
        type='RandomResizedCrop',
        height=768,
        width=768,
        scale=(0.5, 1.0),
        p=0.5),
    dict(
        type='RandomBrightnessContrast',
        brightness_limit=0.1,
        contrast_limit=0.15,
        p=0.5),
    dict(
        type='HueSaturationValue',
        hue_shift_limit=15,
        sat_shift_limit=25,
        val_shift_limit=10,
        p=0.5),
    dict(type='GaussNoise', p=0.3),
    dict(
        type='OneOf',
        transforms=[
            dict(type='Blur', p=1.0),
            dict(type='GaussianBlur', p=1.0),
            dict(type='MedianBlur', blur_limit=5, p=1.0),
            dict(type='MotionBlur', p=1.0)
        ],
        p=0.1)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(768, 768), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.0),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Flip', p=1.0),
                    dict(type='RandomRotate90', p=1.0)
                ],
                p=0.5),
            dict(
                type='RandomResizedCrop',
                height=768,
                width=768,
                scale=(0.5, 1.0),
                p=0.5),
            dict(
                type='RandomBrightnessContrast',
                brightness_limit=0.1,
                contrast_limit=0.15,
                p=0.5),
            dict(
                type='HueSaturationValue',
                hue_shift_limit=15,
                sat_shift_limit=25,
                val_shift_limit=10,
                p=0.5),
            dict(type='GaussNoise', p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(type='Blur', p=1.0),
                    dict(type='GaussianBlur', p=1.0),
                    dict(type='MedianBlur', blur_limit=5, p=1.0),
                    dict(type='MotionBlur', p=1.0)
                ],
                p=0.1)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
valid_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(768, 768),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(768, 768),
        flip=True,
        flip_direction=['horizontal', 'vertical', 'diagonal'],
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=14,
    workers_per_gpu=3,
    train=dict(
        type='CocoDataset',
        ann_file=
        '/opt/ml/detection/dataset_erase2/dataset/cv3_train_pseudo.json',
        img_prefix='/opt/ml/detection/dataset_erase2/dataset/',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(768, 768), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.0),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Flip', p=1.0),
                            dict(type='RandomRotate90', p=1.0)
                        ],
                        p=0.5),
                    dict(
                        type='RandomResizedCrop',
                        height=768,
                        width=768,
                        scale=(0.5, 1.0),
                        p=0.5),
                    dict(
                        type='RandomBrightnessContrast',
                        brightness_limit=0.1,
                        contrast_limit=0.15,
                        p=0.5),
                    dict(
                        type='HueSaturationValue',
                        hue_shift_limit=15,
                        sat_shift_limit=25,
                        val_shift_limit=10,
                        p=0.5),
                    dict(type='GaussNoise', p=0.3),
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(type='Blur', p=1.0),
                            dict(type='GaussianBlur', p=1.0),
                            dict(type='MedianBlur', blur_limit=5, p=1.0),
                            dict(type='MotionBlur', p=1.0)
                        ],
                        p=0.1)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file='/opt/ml/detection/dataset_erase2/dataset/cv_val_3.json',
        img_prefix='/opt/ml/detection/dataset_erase2/dataset/',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(768, 768),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='/opt/ml/detection/dataset_erase2/dataset/test.json',
        img_prefix='/opt/ml/detection/dataset_erase2/dataset/',
        classes=('General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',
                 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(768, 768),
                flip=True,
                flip_direction=['horizontal', 'vertical', 'diagonal'],
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='bbox')
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    betas=(0.9, 0.999),
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.005,
    step=[18, 32])
runner = dict(type='EpochBasedRunner', max_epochs=40)
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=100,
    hooks=[
        dict(type='TextLoggerHook', interval=100),
        dict(
            type='WandbLoggerHook',
            interval=100,
            init_kwargs=dict(
                project='objectdetection', name='dynamic_head_ATSS_pseudo_f3'))
    ])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = './work_dirs/dynamic/3_pseudo/epoch_21.pth'
workflow = [('train', 1), ('val', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'
model = dict(
    type='ATSS',
    backbone=dict(
        type='SwinTransformer',
        embed_dims=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=7,
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.2,
        patch_norm=True,
        out_indices=(0, 1, 2, 3),
        with_cp=False,
        convert_weights=True,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'
        )),
    neck=[
        dict(
            type='FPN',
            in_channels=[96, 192, 384, 768],
            out_channels=256,
            start_level=1,
            add_extra_convs='on_output',
            num_outs=5),
        dict(
            type='DyHead',
            in_channels=256,
            out_channels=256,
            num_blocks=6,
            zero_init_offset=False)
    ],
    bbox_head=dict(
        type='ATSSHead',
        num_classes=10,
        in_channels=256,
        pred_kernel_size=1,
        stacked_convs=0,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            ratios=[1.0],
            octave_base_scale=8,
            scales_per_octave=1,
            strides=[8, 16, 32, 64, 128],
            center_offset=0.5),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[0.1, 0.1, 0.2, 0.2]),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0),
        loss_bbox=dict(type='GIoULoss', loss_weight=2.0),
        loss_centerness=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0)),
    train_cfg=dict(
        assigner=dict(type='ATSSAssigner', topk=9),
        allowed_border=-1,
        pos_weight=-1,
        debug=False),
    test_cfg=dict(
        nms_pre=1000,
        min_bbox_size=0,
        score_thr=0.05,
        nms=dict(type='nms', iou_threshold=0.6),
        max_per_img=100))
work_dir = './work_dirs/dynamic/3_pseudo'
auto_resume = False
gpu_ids = [0]

2022-04-07 01:50:29,318 - mmdet - INFO - Set random seed to 2022, deterministic: False
2022-04-07 01:50:29,837 - mmdet - INFO - load checkpoint from http path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
2022-04-07 01:50:29,964 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-04-07 01:50:30,004 - mmdet - INFO - initialize ATSSHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'atss_cls', 'std': 0.01, 'bias_prob': 0.01}}
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ATSS  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ATSS  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ATSS  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ATSS  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ATSS  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ATSS  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ATSS  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.lateral_convs.0.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.lateral_convs.1.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.lateral_convs.2.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.0.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.0.fpn_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_high.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_high.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_high.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_mid.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_mid.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_mid.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_low.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_low.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_low.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_offset.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.spatial_conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.scale_attn_module.1.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.scale_attn_module.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.task_attn_module.conv1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.task_attn_module.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.task_attn_module.conv2.conv.weight - torch.Size([1024, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.0.task_attn_module.conv2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_high.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_high.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_high.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_mid.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_mid.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_mid.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_low.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_low.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_low.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_offset.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.spatial_conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.scale_attn_module.1.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.scale_attn_module.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.task_attn_module.conv1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.task_attn_module.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.task_attn_module.conv2.conv.weight - torch.Size([1024, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.1.task_attn_module.conv2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_high.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_high.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_high.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_mid.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_mid.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_mid.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_low.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_low.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_low.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_offset.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.spatial_conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.scale_attn_module.1.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.scale_attn_module.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.task_attn_module.conv1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.task_attn_module.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.task_attn_module.conv2.conv.weight - torch.Size([1024, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.2.task_attn_module.conv2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_high.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_high.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_high.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_mid.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_mid.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_mid.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_low.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_low.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_low.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_offset.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.spatial_conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.scale_attn_module.1.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.scale_attn_module.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.task_attn_module.conv1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.task_attn_module.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.task_attn_module.conv2.conv.weight - torch.Size([1024, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.3.task_attn_module.conv2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_high.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_high.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_high.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_mid.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_mid.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_mid.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_low.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_low.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_low.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_offset.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.spatial_conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.scale_attn_module.1.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.scale_attn_module.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.task_attn_module.conv1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.task_attn_module.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.task_attn_module.conv2.conv.weight - torch.Size([1024, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.4.task_attn_module.conv2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_high.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_high.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_high.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_mid.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_mid.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_mid.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_low.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_low.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_low.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_offset.weight - torch.Size([27, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.spatial_conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.scale_attn_module.1.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.scale_attn_module.1.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.task_attn_module.conv1.conv.weight - torch.Size([64, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.task_attn_module.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.task_attn_module.conv2.conv.weight - torch.Size([1024, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of ATSS  

neck.1.dyhead_blocks.5.task_attn_module.conv2.conv.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of ATSS  

bbox_head.atss_cls.weight - torch.Size([10, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.atss_cls.bias - torch.Size([10]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.atss_reg.weight - torch.Size([4, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.atss_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.atss_centerness.weight - torch.Size([1, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.atss_centerness.bias - torch.Size([1]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.scales.0.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of ATSS  

bbox_head.scales.1.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of ATSS  

bbox_head.scales.2.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of ATSS  

bbox_head.scales.3.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of ATSS  

bbox_head.scales.4.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of ATSS  
2022-04-07 01:50:34,041 - mmdet - INFO - load checkpoint from local path: ./work_dirs/dynamic/3_pseudo/epoch_21.pth
2022-04-07 01:50:34,455 - mmdet - INFO - resumed epoch 21, iter 13167
2022-04-07 01:50:34,458 - mmdet - INFO - Start running, host: root@71b0d7392d91, work_dir: /opt/ml/detection/baseline/mmdetection/work_dirs/dynamic/3_pseudo
2022-04-07 01:50:34,459 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) WandbLoggerHook                    
 -------------------- 
2022-04-07 01:50:34,459 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 40 epochs
2022-04-07 01:50:34,459 - mmdet - INFO - Checkpoints will be saved to /opt/ml/detection/baseline/mmdetection/work_dirs/dynamic/3_pseudo by HardDiskBackend.
2022-04-07 01:55:52,409 - mmdet - INFO - Epoch [22][100/627]	lr: 1.000e-05, eta: 10:13:27, time: 3.116, data_time: 0.058, memory: 28243, loss_cls: 0.2404, loss_bbox: 0.2848, loss_centerness: 0.5980, loss: 1.1232
2022-04-07 02:01:00,048 - mmdet - INFO - Epoch [22][200/627]	lr: 1.000e-05, eta: 10:04:24, time: 3.076, data_time: 0.025, memory: 28243, loss_cls: 0.2277, loss_bbox: 0.2734, loss_centerness: 0.5971, loss: 1.0982
2022-04-07 02:06:07,372 - mmdet - INFO - Epoch [22][300/627]	lr: 1.000e-05, eta: 9:57:46, time: 3.073, data_time: 0.025, memory: 28243, loss_cls: 0.2265, loss_bbox: 0.2660, loss_centerness: 0.5968, loss: 1.0893
2022-04-07 02:11:14,706 - mmdet - INFO - Epoch [22][400/627]	lr: 1.000e-05, eta: 9:51:54, time: 3.073, data_time: 0.024, memory: 28243, loss_cls: 0.2253, loss_bbox: 0.2661, loss_centerness: 0.5967, loss: 1.0881
2022-04-07 02:16:21,942 - mmdet - INFO - Epoch [22][500/627]	lr: 1.000e-05, eta: 9:46:17, time: 3.072, data_time: 0.025, memory: 28243, loss_cls: 0.2372, loss_bbox: 0.2776, loss_centerness: 0.5975, loss: 1.1123
2022-04-07 02:21:29,262 - mmdet - INFO - Epoch [22][600/627]	lr: 1.000e-05, eta: 9:40:52, time: 3.073, data_time: 0.024, memory: 28243, loss_cls: 0.2289, loss_bbox: 0.2557, loss_centerness: 0.5965, loss: 1.0811
2022-04-07 02:22:52,232 - mmdet - INFO - Saving checkpoint at 22 epochs
2022-04-07 02:24:52,122 - mmdet - INFO - Evaluating bbox...
2022-04-07 02:24:59,997 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.461
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.596
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.187
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.543
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.006
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.373
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.733

2022-04-07 02:25:00,110 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 02:25:00,110 - mmdet - INFO - Epoch(val) [22][972]	bbox_mAP: 0.4610, bbox_mAP_50: 0.5960, bbox_mAP_75: 0.4950, bbox_mAP_s: 0.0010, bbox_mAP_m: 0.1870, bbox_mAP_l: 0.5430, bbox_mAP_copypaste: 0.461 0.596 0.495 0.001 0.187 0.543
2022-04-07 02:25:54,835 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 02:25:54,835 - mmdet - INFO - Epoch(val) [22][70]	loss_cls: 0.3320, loss_bbox: 0.3774, loss_centerness: 0.6061, loss: 1.3155
2022-04-07 02:31:05,801 - mmdet - INFO - Epoch [23][100/627]	lr: 1.000e-05, eta: 9:13:45, time: 3.109, data_time: 0.059, memory: 28243, loss_cls: 0.2227, loss_bbox: 0.2696, loss_centerness: 0.5975, loss: 1.0898
2022-04-07 02:36:13,379 - mmdet - INFO - Epoch [23][200/627]	lr: 1.000e-05, eta: 9:11:09, time: 3.076, data_time: 0.026, memory: 28243, loss_cls: 0.2179, loss_bbox: 0.2655, loss_centerness: 0.5969, loss: 1.0803
2022-04-07 02:41:20,702 - mmdet - INFO - Epoch [23][300/627]	lr: 1.000e-05, eta: 9:07:58, time: 3.073, data_time: 0.026, memory: 28243, loss_cls: 0.2257, loss_bbox: 0.2602, loss_centerness: 0.5971, loss: 1.0829
2022-04-07 02:46:27,965 - mmdet - INFO - Epoch [23][400/627]	lr: 1.000e-05, eta: 9:04:23, time: 3.073, data_time: 0.026, memory: 28243, loss_cls: 0.2202, loss_bbox: 0.2484, loss_centerness: 0.5962, loss: 1.0649
2022-04-07 02:51:35,155 - mmdet - INFO - Epoch [23][500/627]	lr: 1.000e-05, eta: 9:00:31, time: 3.072, data_time: 0.026, memory: 28243, loss_cls: 0.2168, loss_bbox: 0.2583, loss_centerness: 0.5962, loss: 1.0712
2022-04-07 02:56:42,572 - mmdet - INFO - Epoch [23][600/627]	lr: 1.000e-05, eta: 8:56:29, time: 3.074, data_time: 0.026, memory: 28243, loss_cls: 0.2180, loss_bbox: 0.2661, loss_centerness: 0.5969, loss: 1.0810
2022-04-07 02:58:05,531 - mmdet - INFO - Saving checkpoint at 23 epochs
2022-04-07 03:00:04,991 - mmdet - INFO - Evaluating bbox...
2022-04-07 03:00:12,636 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.599
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.192
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.547
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.005
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.367
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.736

2022-04-07 03:00:12,750 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 03:00:12,750 - mmdet - INFO - Epoch(val) [23][972]	bbox_mAP: 0.4630, bbox_mAP_50: 0.5990, bbox_mAP_75: 0.4960, bbox_mAP_s: 0.0020, bbox_mAP_m: 0.1920, bbox_mAP_l: 0.5470, bbox_mAP_copypaste: 0.463 0.599 0.496 0.002 0.192 0.547
2022-04-07 03:01:07,423 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 03:01:07,424 - mmdet - INFO - Epoch(val) [23][70]	loss_cls: 0.3264, loss_bbox: 0.3706, loss_centerness: 0.6066, loss: 1.3036
2022-04-07 03:06:17,863 - mmdet - INFO - Epoch [24][100/627]	lr: 1.000e-05, eta: 8:40:44, time: 3.104, data_time: 0.058, memory: 28243, loss_cls: 0.2158, loss_bbox: 0.2616, loss_centerness: 0.5966, loss: 1.0739
2022-04-07 03:11:24,990 - mmdet - INFO - Epoch [24][200/627]	lr: 1.000e-05, eta: 8:37:09, time: 3.071, data_time: 0.025, memory: 28243, loss_cls: 0.2126, loss_bbox: 0.2438, loss_centerness: 0.5943, loss: 1.0508
2022-04-07 03:16:32,295 - mmdet - INFO - Epoch [24][300/627]	lr: 1.000e-05, eta: 8:33:23, time: 3.073, data_time: 0.026, memory: 28243, loss_cls: 0.2219, loss_bbox: 0.2664, loss_centerness: 0.5966, loss: 1.0850
2022-04-07 03:21:39,231 - mmdet - INFO - Epoch [24][400/627]	lr: 1.000e-05, eta: 8:29:25, time: 3.069, data_time: 0.025, memory: 28243, loss_cls: 0.2098, loss_bbox: 0.2454, loss_centerness: 0.5942, loss: 1.0494
2022-04-07 03:26:46,614 - mmdet - INFO - Epoch [24][500/627]	lr: 1.000e-05, eta: 8:25:22, time: 3.074, data_time: 0.026, memory: 28243, loss_cls: 0.2172, loss_bbox: 0.2616, loss_centerness: 0.5962, loss: 1.0750
2022-04-07 03:31:53,686 - mmdet - INFO - Epoch [24][600/627]	lr: 1.000e-05, eta: 8:21:10, time: 3.071, data_time: 0.025, memory: 28243, loss_cls: 0.2145, loss_bbox: 0.2564, loss_centerness: 0.5966, loss: 1.0675
2022-04-07 03:33:16,679 - mmdet - INFO - Saving checkpoint at 24 epochs
2022-04-07 03:35:16,156 - mmdet - INFO - Evaluating bbox...
2022-04-07 03:35:24,002 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.603
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.199
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.376
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.737

2022-04-07 03:35:24,118 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 03:35:24,119 - mmdet - INFO - Epoch(val) [24][972]	bbox_mAP: 0.4690, bbox_mAP_50: 0.6030, bbox_mAP_75: 0.4960, bbox_mAP_s: 0.0030, bbox_mAP_m: 0.1990, bbox_mAP_l: 0.5520, bbox_mAP_copypaste: 0.469 0.603 0.496 0.003 0.199 0.552
2022-04-07 03:36:18,870 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 03:36:18,870 - mmdet - INFO - Epoch(val) [24][70]	loss_cls: 0.3359, loss_bbox: 0.3796, loss_centerness: 0.6074, loss: 1.3230
2022-04-07 03:41:29,748 - mmdet - INFO - Epoch [25][100/627]	lr: 1.000e-05, eta: 8:09:05, time: 3.109, data_time: 0.059, memory: 28243, loss_cls: 0.2131, loss_bbox: 0.2654, loss_centerness: 0.5978, loss: 1.0763
2022-04-07 03:46:36,851 - mmdet - INFO - Epoch [25][200/627]	lr: 1.000e-05, eta: 8:05:05, time: 3.071, data_time: 0.026, memory: 28243, loss_cls: 0.2054, loss_bbox: 0.2394, loss_centerness: 0.5951, loss: 1.0400
2022-04-07 03:51:44,059 - mmdet - INFO - Epoch [25][300/627]	lr: 1.000e-05, eta: 8:00:59, time: 3.072, data_time: 0.026, memory: 28243, loss_cls: 0.2206, loss_bbox: 0.2605, loss_centerness: 0.5967, loss: 1.0778
2022-04-07 03:56:51,109 - mmdet - INFO - Epoch [25][400/627]	lr: 1.000e-05, eta: 7:56:46, time: 3.070, data_time: 0.025, memory: 28243, loss_cls: 0.2139, loss_bbox: 0.2613, loss_centerness: 0.5965, loss: 1.0717
2022-04-07 04:01:58,501 - mmdet - INFO - Epoch [25][500/627]	lr: 1.000e-05, eta: 7:52:31, time: 3.074, data_time: 0.026, memory: 28243, loss_cls: 0.2097, loss_bbox: 0.2432, loss_centerness: 0.5959, loss: 1.0488
2022-04-07 04:07:05,856 - mmdet - INFO - Epoch [25][600/627]	lr: 1.000e-05, eta: 7:48:11, time: 3.074, data_time: 0.026, memory: 28243, loss_cls: 0.2167, loss_bbox: 0.2620, loss_centerness: 0.5965, loss: 1.0752
2022-04-07 04:08:28,823 - mmdet - INFO - Saving checkpoint at 25 epochs
2022-04-07 04:10:26,529 - mmdet - INFO - Evaluating bbox...
2022-04-07 04:10:34,440 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.607
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.002
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.207
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.007
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.375
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.738

2022-04-07 04:10:34,544 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 04:10:34,544 - mmdet - INFO - Epoch(val) [25][972]	bbox_mAP: 0.4700, bbox_mAP_50: 0.6070, bbox_mAP_75: 0.5040, bbox_mAP_s: 0.0020, bbox_mAP_m: 0.2070, bbox_mAP_l: 0.5520, bbox_mAP_copypaste: 0.470 0.607 0.504 0.002 0.207 0.552
2022-04-07 04:11:29,103 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 04:11:29,103 - mmdet - INFO - Epoch(val) [25][70]	loss_cls: 0.3276, loss_bbox: 0.3724, loss_centerness: 0.6078, loss: 1.3078
2022-04-07 04:16:39,751 - mmdet - INFO - Epoch [26][100/627]	lr: 1.000e-05, eta: 7:37:52, time: 3.106, data_time: 0.059, memory: 28243, loss_cls: 0.2114, loss_bbox: 0.2493, loss_centerness: 0.5952, loss: 1.0559
2022-04-07 04:21:47,128 - mmdet - INFO - Epoch [26][200/627]	lr: 1.000e-05, eta: 7:33:38, time: 3.074, data_time: 0.026, memory: 28243, loss_cls: 0.2102, loss_bbox: 0.2538, loss_centerness: 0.5956, loss: 1.0597
2022-04-07 04:26:54,611 - mmdet - INFO - Epoch [26][300/627]	lr: 1.000e-05, eta: 7:29:20, time: 3.075, data_time: 0.026, memory: 28243, loss_cls: 0.2140, loss_bbox: 0.2572, loss_centerness: 0.5964, loss: 1.0676
2022-04-07 04:32:01,963 - mmdet - INFO - Epoch [26][400/627]	lr: 1.000e-05, eta: 7:24:59, time: 3.073, data_time: 0.026, memory: 28243, loss_cls: 0.2072, loss_bbox: 0.2496, loss_centerness: 0.5953, loss: 1.0520
2022-04-07 04:37:09,393 - mmdet - INFO - Epoch [26][500/627]	lr: 1.000e-05, eta: 7:20:35, time: 3.074, data_time: 0.026, memory: 28243, loss_cls: 0.2072, loss_bbox: 0.2483, loss_centerness: 0.5958, loss: 1.0514
2022-04-07 04:42:16,514 - mmdet - INFO - Epoch [26][600/627]	lr: 1.000e-05, eta: 7:16:07, time: 3.071, data_time: 0.026, memory: 28243, loss_cls: 0.2016, loss_bbox: 0.2382, loss_centerness: 0.5943, loss: 1.0341
2022-04-07 04:43:39,499 - mmdet - INFO - Saving checkpoint at 26 epochs
2022-04-07 04:45:38,598 - mmdet - INFO - Evaluating bbox...
2022-04-07 04:45:46,151 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.609
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.507
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.003
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.185
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.561
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.379
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.743

2022-04-07 04:45:46,248 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 04:45:46,248 - mmdet - INFO - Epoch(val) [26][972]	bbox_mAP: 0.4750, bbox_mAP_50: 0.6090, bbox_mAP_75: 0.5070, bbox_mAP_s: 0.0030, bbox_mAP_m: 0.1850, bbox_mAP_l: 0.5610, bbox_mAP_copypaste: 0.475 0.609 0.507 0.003 0.185 0.561
2022-04-07 04:46:40,835 - mmdet - INFO - Exp name: myconfig.py
2022-04-07 04:46:40,836 - mmdet - INFO - Epoch(val) [26][70]	loss_cls: 0.3226, loss_bbox: 0.3707, loss_centerness: 0.6074, loss: 1.3008
2022-04-07 04:51:51,693 - mmdet - INFO - Epoch [27][100/627]	lr: 1.000e-05, eta: 7:06:51, time: 3.108, data_time: 0.059, memory: 28243, loss_cls: 0.2053, loss_bbox: 0.2408, loss_centerness: 0.5951, loss: 1.0411
